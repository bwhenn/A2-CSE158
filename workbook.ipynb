{
          "cells": [
                    {
                              "cell_type": "code",
                              "execution_count": 3,
                              "id": "69de8252",
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "import gzip\n",
                                        "import os\n",
                                        "import datetime \n",
                                        "import struct\n",
                                        "import numpy as np\n",
                                        "from collections import defaultdict, Counter\n",
                                        "from typing import Dict, Iterable, Tuple, List, Any\n",
                                        "\n",
                                        "IMAGE_FEATURES_DATA_PATH = \"data/Behance_Image_Features.b\"\n",
                                        "ITEMS_TO_OWNERS_DATA_PATH = \"data/Behance_Item_to_Owners.gz\"\n",
                                        "APPRECIATE_DATA_PATH = \"data/Behance_appreciate_1M.gz\""
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "id": "c9049e36",
                              "metadata": {},
                              "source": [
                                        "# Assignment 2 – Behance Like Prediction"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "id": "32f6bce9",
                              "metadata": {},
                              "source": [
                                        "## 1. Predictive Task & Evaluation"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "id": "191e3f08",
                              "metadata": {},
                              "source": [
                                        "Predict whether a user will “like” (appreciate) an image."
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "id": "44ab1d62",
                              "metadata": {},
                              "source": [
                                        "## 2. Exploratory Data Analysis (EDA)"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "id": "99d0607b",
                              "metadata": {},
                              "source": []
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 4,
                              "id": "0a6c5a8d",
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "def process_gzipped_text_file(path: str) -> Iterable[Tuple[str, ...]]:\n",
                                        "    try:\n",
                                        "        with open(path, \"rt\", encoding=\"utf-8\") as f:\n",
                                        "            for line in f:\n",
                                        "                segments = tuple(line.strip().split())\n",
                                        "                yield segments\n",
                                        "    except FileNotFoundError:\n",
                                        "        print(f\"Error: File not found at {path}\")\n",
                                        "    except Exception as e:\n",
                                        "        print(f\"An error occurred: {e}\")\n",
                                        "\n",
                                        "def readImageFeatures(path: str):\n",
                                        "    f = open(path, \"rb\")\n",
                                        "    while True:\n",
                                        "        itemId = f.read(8)\n",
                                        "        if not itemId or len(itemId) < 8:\n",
                                        "            break\n",
                                        "        feature = struct.unpack(\"f\" * 4096, f.read(4 * 4096))\n",
                                        "        yield itemId, feature\n",
                                        "\n",
                                        "def _decode_item_id(raw_id):\n",
                                        "    if isinstance(raw_id, (bytes, bytearray)):\n",
                                        "        return raw_id.decode(\"utf-8\")\n",
                                        "    return str(raw_id)"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": null,
                              "id": "d1055ff5",
                              "metadata": {},
                              "outputs": [
                                        {
                                                  "name": "stdout",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "63497\n"
                                                  ]
                                        }
                              ],
                              "source": [
                                        "g1 = readImageFeatures(path=IMAGE_FEATURES_DATA_PATH)\n",
                                        "g2 = process_gzipped_text_file(path=ITEMS_TO_OWNERS_DATA_PATH)\n",
                                        "g3 = process_gzipped_text_file(path=APPRECIATE_DATA_PATH)\n",
                                        "\n",
                                        "# Item ownership lookups\n",
                                        "item_to_owner: Dict[str, str] = {}\n",
                                        "owner_to_items: Dict[str, set] = defaultdict(set)\n",
                                        "for row in g2:\n",
                                        "    item, owner = row[0], row[1]\n",
                                        "    item_to_owner[item] = owner\n",
                                        "    owner_to_items[owner].add(item)\n",
                                        "\n",
                                        "# Interaction histories\n",
                                        "user_to_items: Dict[str, List[Tuple[str, Any]]] = defaultdict(list)  # user -> list of (item, timestamp)\n",
                                        "item_to_users: Dict[str, List[Tuple[str, Any]]] = defaultdict(list)  # item -> list of (user, timestamp)\n",
                                        "for user_id, item_id, ts in g3:\n",
                                        "    ts_int = int(ts) if ts.isdigit() else ts\n",
                                        "    user_to_items[user_id].append((item_id, ts_int))\n",
                                        "    item_to_users[item_id].append((user_id, ts_int))"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 6,
                              "id": "f8c437b1",
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "def summarize_counter(counter: Counter) -> Dict[str, float]:\n",
                                        "    if not counter:\n",
                                        "        return {\"count\": 0, \"mean\": 0.0, \"median\": 0.0, \"p90\": 0.0, \"p99\": 0.0, \"max\": 0}\n",
                                        "    vals = np.fromiter(counter.values(), dtype=np.int64)\n",
                                        "    return {\n",
                                        "        \"count\": len(counter),\n",
                                        "        \"mean\": float(vals.mean()),\n",
                                        "        \"median\": float(np.percentile(vals, 50)),\n",
                                        "        \"p90\": float(np.percentile(vals, 90)),\n",
                                        "        \"p99\": float(np.percentile(vals, 99)),\n",
                                        "        \"max\": int(vals.max()),\n",
                                        "    }\n",
                                        "\n",
                                        "def load_feature_ids(path: str, limit: int = None) -> set:\n",
                                        "    ids = set()\n",
                                        "    for idx, (raw_id, _) in enumerate(readImageFeatures(path)):\n",
                                        "        ids.add(_decode_item_id(raw_id))\n",
                                        "        if limit and idx + 1 >= limit:\n",
                                        "            break\n",
                                        "    return ids\n",
                                        "\n",
                                        "def compute_eda(\n",
                                        "    ownership_path: str = ITEMS_TO_OWNERS_DATA_PATH,\n",
                                        "    interaction_path: str = APPRECIATE_DATA_PATH\n",
                                        ") -> Dict[str, Any]:\n",
                                        "    owner_item_counts = Counter()\n",
                                        "    with open(ownership_path, \"rt\", encoding=\"utf-8\") as f:\n",
                                        "        for line in f:\n",
                                        "            parts = line.strip().split()\n",
                                        "            if len(parts) >= 2:\n",
                                        "                owner_item_counts[parts[1]] += 1\n",
                                        "    ownership_summary = summarize_counter(owner_item_counts)\n",
                                        "\n",
                                        "    user_inter_counts = Counter()\n",
                                        "    item_inter_counts = Counter()\n",
                                        "    day_bins = Counter()\n",
                                        "    ts_min, ts_max = None, None\n",
                                        "    with open(interaction_path, \"rt\", encoding=\"utf-8\") as f:\n",
                                        "        for line in f:\n",
                                        "            parts = line.strip().split()\n",
                                        "            if len(parts) >= 3:\n",
                                        "                user, item, ts = parts[0], parts[1], int(parts[2])\n",
                                        "                user_inter_counts[user] += 1\n",
                                        "                item_inter_counts[item] += 1\n",
                                        "                day_bins[ts // 86400] += 1\n",
                                        "                ts_min = ts if ts_min is None else min(ts_min, ts)\n",
                                        "                ts_max = ts if ts_max is None else max(ts_max, ts)\n",
                                        "\n",
                                        "    cold_users_1 = sum(1 for v in user_inter_counts.values() if v == 1)\n",
                                        "    cold_items_1 = sum(1 for v in item_inter_counts.values() if v == 1)\n",
                                        "    cold_users_3 = sum(1 for v in user_inter_counts.values() if v <= 3)\n",
                                        "    cold_items_3 = sum(1 for v in item_inter_counts.values() if v <= 3)\n",
                                        "\n",
                                        "    interaction_summary = {\n",
                                        "        \"total_interactions\": int(sum(user_inter_counts.values())),\n",
                                        "        \"users\": summarize_counter(user_inter_counts),\n",
                                        "        \"items\": summarize_counter(item_inter_counts),\n",
                                        "        \"timestamp_range\": (ts_min, ts_max),\n",
                                        "        \"cold_start\": {\n",
                                        "            \"users_eq1\": cold_users_1,\n",
                                        "            \"items_eq1\": cold_items_1,\n",
                                        "            \"users_le3\": cold_users_3,\n",
                                        "            \"items_le3\": cold_items_3,\n",
                                        "        },\n",
                                        "        \"top_days\": day_bins.most_common(5),\n",
                                        "    }\n",
                                        "\n",
                                        "\n",
                                        "    return {\n",
                                        "        \"ownership\": ownership_summary,\n",
                                        "        \"interactions\": interaction_summary,\n",
                                        "    }\n",
                                        "\n",
                                        "def print_eda_report(eda: Dict[str, Any]) -> None:\n",
                                        "    print(\"\\n=== Exploratory Data Analysis ===\")\n",
                                        "    own = eda[\"ownership\"]\n",
                                        "    print(\n",
                                        "        f\"Ownership: {int(own.get('count', 0)):,} owners, \"\n",
                                        "        f\"avg items/owner={own.get('mean', 0):.2f}, median={own.get('median', 0):.0f}, \"\n",
                                        "        f\"p90={own.get('p90', 0):.0f}, p99={own.get('p99', 0):.0f}, max={own.get('max', 0):,}\"\n",
                                        "    )\n",
                                        "\n",
                                        "    inter = eda[\"interactions\"]\n",
                                        "    print(f\"\\nInteractions: {inter['total_interactions']:,}\")\n",
                                        "    u = inter[\"users\"]\n",
                                        "    print(\n",
                                        "        f\"Users: {int(u.get('count', 0)):,}; \"\n",
                                        "        f\"avg={u.get('mean', 0):.2f}, median={u.get('median', 0):.0f}, \"\n",
                                        "        f\"p90={u.get('p90', 0):.0f}, p99={u.get('p99', 0):.0f}, max={u.get('max', 0):,}\"\n",
                                        "    )\n",
                                        "    it = inter[\"items\"]\n",
                                        "    print(\n",
                                        "        f\"Items: {int(it.get('count', 0)):,}; \"\n",
                                        "        f\"avg={it.get('mean', 0):.2f}, median={it.get('median', 0):.0f}, \"\n",
                                        "        f\"p90={it.get('p90', 0):.0f}, p99={it.get('p99', 0):.0f}, max={it.get('max', 0):,}\"\n",
                                        "    )\n",
                                        "    ts_min, ts_max = inter[\"timestamp_range\"]\n",
                                        "    print(f\"Timestamps span: {ts_min} to {ts_max} \"\n",
                                        "          f\"({datetime.datetime.fromtimestamp(ts_max, tz=datetime.timezone.utc).date()})\")\n",
                                        "\n",
                                        "    cold = inter[\"cold_start\"]\n",
                                        "    print(\n",
                                        "        f\"Cold-start: users with 1 interaction={cold['users_eq1']:,}, <=3={cold['users_le3']:,}; \"\n",
                                        "        f\"items with 1 interaction={cold['items_eq1']:,}, <=3={cold['items_le3']:,}\"\n",
                                        "    )\n",
                                        "\n",
                                        "    top_days = [\n",
                                        "        f\"{datetime.datetime.fromtimestamp(day * 86400, tz=datetime.timezone.utc).date()}: {count:,}\"\n",
                                        "        for day, count in inter[\"top_days\"]\n",
                                        "    ]\n",
                                        "    print(\"Top 5 days by interactions: \" + (\"; \".join(top_days) if top_days else \"n/a\"))"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 7,
                              "id": "e3a46b75",
                              "metadata": {},
                              "outputs": [
                                        {
                                                  "name": "stdout",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "\n",
                                                            "=== Exploratory Data Analysis ===\n",
                                                            "Ownership: 51,487 owners, avg items/owner=3.62, median=2, p90=8, p99=21, max=153\n",
                                                            "\n",
                                                            "Interactions: 1,000,000\n",
                                                            "Users: 63,497; avg=15.75, median=4, p90=32, p99=197, max=2,260\n",
                                                            "Items: 178,788; avg=5.59, median=2, p90=8, p99=67, max=1,793\n",
                                                            "Timestamps span: 1307583271 to 1321254674 (2011-11-14)\n",
                                                            "Cold-start: users with 1 interaction=15,938, <=3=29,875; items with 1 interaction=84,996, <=3=136,787\n",
                                                            "Top 5 days by interactions: 2011-11-08: 9,862; 2011-11-02: 9,485; 2011-10-24: 9,482; 2011-11-09: 9,453; 2011-10-03: 9,340\n"
                                                  ]
                                        }
                              ],
                              "source": [
                                        "eda_stats = compute_eda()  \n",
                                        "print_eda_report(eda_stats)"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "id": "6e3cc0a1",
                              "metadata": {},
                              "source": [
                                        "### Dataset Overview\n",
                                        "- Interactions: user-item-timestamp appreciates.\n",
                                        "- Ownership: item-to-owner mapping (creator).\n",
                                        "- Visual features: 4,096-d image embeddings per item.\n",
                                        "\n",
                                        "### Basic Counts\n",
                                        "- Ownership: 51,487 owners; avg items/owner 3.62; median 2; p90 8; p99 21; max 153.\n",
                                        "- Interactions: 1,000,000 appreciates across 63,497 users and 178,788 items.\n",
                                        "\n",
                                        "### Interaction Shape\n",
                                        "- Users: avg 15.75 interactions; median 4; p90 32; p99 197; max 2,260.\n",
                                        "- Items: avg 5.59 interactions; median 2; p90 8; p99 67; max 1,793.\n",
                                        "- Interpretation: heavily long-tailed; a small head of very active users/items.\n",
                                        "\n",
                                        "### Cold-Start Slices\n",
                                        "- Users with 1 interaction: 15,938; <=3: 29,875.\n",
                                        "- Items with 1 interaction: 84,996; <=3: 136,787.\n",
                                        "- Implication: many users/items are data-poor; content and popularity backstops matter.\n",
                                        "\n",
                                        "### Temporal Characteristics\n",
                                        "- Timestamp span: 1307583271 to 1321254674 (up to 2011-11-14 UTC).\n",
                                        "- Top 5 days by volume: 2011-11-08 (9,862); 2011-11-02 (9,485); 2011-10-24 (9,482); 2011-11-09 (9,453); 2011-10-03 (9,340).\n",
                                        "- Note: train/val/test splits should respect chronology to prevent leakage.\n",
                                        "\n",
                                        "### Modeling Implications\n",
                                        "- Expect sparsity and imbalance; use regularization and sensible negatives.\n",
                                        "- Mitigate cold-start with image features and owner-level signals.\n",
                                        "- Use time-aware validation to benchmark models realistically.\n"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "id": "9e6d4149",
                              "metadata": {},
                              "source": [
                                        "## 3. Modeling"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "id": "40705d8e",
                              "metadata": {},
                              "source": [
                                        "Temporal split here means you sort each user's interactions by timestamp and then carve off the most recent interactions for validation and test, keeping only the earlier interactions for training. Users with fewer than 3 interactions are kept entirely in train."
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 8,
                              "id": "dc4bf5a9",
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# Temporal split \n",
                                        "def temporal_train_val_test_split(histories, val_ratio=0.1, test_ratio=0.1):\n",
                                        "    train, val, test = defaultdict(list), defaultdict(list), defaultdict(list)\n",
                                        "    for user, events in histories.items():\n",
                                        "        ordered = sorted(events, key=lambda x: x[1])\n",
                                        "        n = len(ordered)\n",
                                        "        if n < 3:\n",
                                        "            train[user].extend(ordered)\n",
                                        "            continue\n",
                                        "        test_size = max(1, int(n * test_ratio))\n",
                                        "        val_size = max(1, int(n * val_ratio))\n",
                                        "        train[user].extend(ordered[: n - val_size - test_size])\n",
                                        "        val[user].extend(ordered[n - val_size - test_size : n - test_size])\n",
                                        "        test[user].extend(ordered[n - test_size :])\n",
                                        "    return train, val, test\n",
                                        "\n",
                                        "train_histories, val_histories, test_histories = temporal_train_val_test_split(user_to_items)"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "id": "d65313bf",
                              "metadata": {},
                              "source": [
                                        "## 4. Evaluation & Results"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "id": "e68660e4",
                              "metadata": {},
                              "source": [
                                        "Calculate precision@k and recall@k"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 9,
                              "id": "3ee3a7a1",
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "def calculate_metrics(ranked_items, actual_items, k=10):\n",
                                        "    top_k = ranked_items[:k]\n",
                                        "    acc = 0\n",
                                        "    actual_items = set(actual_items)\n",
                                        "\n",
                                        "    for item in top_k:\n",
                                        "        if item in actual_items:\n",
                                        "            acc += 1\n",
                                        "    \n",
                                        "    precision = acc / k\n",
                                        "    recall = acc / len(actual_items) if len(actual_items) > 0 else .0\n",
                                        "\n",
                                        "    return precision, recall"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "id": "7d07f7cf",
                              "metadata": {},
                              "source": [
                                        "Popularity baseline model"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 25,
                              "id": "22ba71c1",
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "from collections import Counter\n",
                                        "\n",
                                        "item_popularity = Counter()\n",
                                        "for user, history in train_histories.items():\n",
                                        "    for item, timestamp in history:\n",
                                        "        item_popularity[item] += 1\n",
                                        "\n",
                                        "most_popular = [item for item, count in item_popularity.most_common(100)]\n",
                                        "\n",
                                        "def predict_most_popular(user_id):\n",
                                        "    return most_popular"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "id": "9b1e461f",
                              "metadata": {},
                              "source": [
                                        "Evaluation"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 34,
                              "id": "e57921c7",
                              "metadata": {},
                              "outputs": [
                                        {
                                                  "name": "stdout",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "Mean Precision@10:  0.00192\n",
                                                            "Mean Recall@10:     0.01196\n",
                                                            "Mean Precision@100:  0.00110\n",
                                                            "Mean Recall@100:     0.06388\n"
                                                  ]
                                        }
                              ],
                              "source": [
                                        "import numpy as np\n",
                                        "\n",
                                        "def evaluate_model(pred_fun, test_data, k=10):\n",
                                        "    precisions = []\n",
                                        "    recalls = []\n",
                                        "\n",
                                        "    for user, history in test_data.items():\n",
                                        "        actual_items = [item for item, ts in history]\n",
                                        "        predictions = pred_fun(user)\n",
                                        "        precision, recall = calculate_metrics(predictions, actual_items, k)\n",
                                        "        precisions.append(precision)\n",
                                        "        recalls.append(recall)\n",
                                        "    \n",
                                        "    print(f'Mean Precision@{k}:  {np.mean(precisions):.5f}')\n",
                                        "    print(f'Mean Recall@{k}:     {np.mean(recalls):.5f}')\n",
                                        "\n",
                                        "evaluate_model(predict_most_popular, test_histories, k=10)\n",
                                        "evaluate_model(predict_most_popular, test_histories, k=100)"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "id": "91d2e07f",
                              "metadata": {},
                              "source": [
                                        "Stratified evaluation for cold start users"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 35,
                              "id": "191ab3af",
                              "metadata": {},
                              "outputs": [
                                        {
                                                  "name": "stdout",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "Cold start users (17326)\n",
                                                            "Mean Precision@10:  0.00147\n",
                                                            "Mean Recall@10:     0.01466\n",
                                                            "Warm start users (21845)\n",
                                                            "Mean Precision@10:  0.00229\n",
                                                            "Mean Recall@10:     0.00982\n"
                                                  ]
                                        }
                              ],
                              "source": [
                                        "def evaluate_subset(pred_fun, users, test_data, k=10):\n",
                                        "    users = set(users)\n",
                                        "    precisions = []\n",
                                        "    recalls = []\n",
                                        "\n",
                                        "    for user, history in test_data.items():\n",
                                        "        if user not in users:\n",
                                        "            continue\n",
                                        "        actual_items = [item for item, ts in history]\n",
                                        "        predictions = pred_fun(user)\n",
                                        "        precision, recall = calculate_metrics(predictions, actual_items, k)\n",
                                        "        precisions.append(precision)\n",
                                        "        recalls.append(recall)\n",
                                        "    \n",
                                        "    print(f'Mean Precision@{k}:  {np.mean(precisions):.5f}')\n",
                                        "    print(f'Mean Recall@{k}:     {np.mean(recalls):.5f}')\n",
                                        "\n",
                                        "def evaluate_stratified(pred_fun, train_data, test_data, k=10):\n",
                                        "    cold_users = []\n",
                                        "    warm_users = []\n",
                                        "\n",
                                        "    for user, history in test_data.items():\n",
                                        "        train_count = len(train_data.get(user, []))\n",
                                        "        if train_count <= 5:\n",
                                        "            cold_users.append(user)\n",
                                        "        else:\n",
                                        "            warm_users.append(user)\n",
                                        "    \n",
                                        "    print(f'Cold start users ({len(cold_users)})')\n",
                                        "    evaluate_subset(pred_fun, cold_users, test_data, k)\n",
                                        "    print(f'Warm start users ({len(warm_users)})')\n",
                                        "    evaluate_subset(pred_fun, warm_users, test_data, k)\n",
                                        "\n",
                                        "evaluate_stratified(predict_most_popular, train_histories, test_histories, 10)"
                              ]
                    },
                    {
                              "cell_type": "markdown",
                              "id": "85bcc132",
                              "metadata": {},
                              "source": [
                                        "## 5. Related Work\n",
                                        "\n",
                                        "Our project fits into a long line of research on systems that suggest items to users based on\n",
                                        "their past behavior, such as likes or clicks, and on using image information to make better\n",
                                        "recommendations.\n",
                                        "\n",
                                        "**Using past likes and clicks to make recommendations:**  \n",
                                        "Many existing systems only see whether a user clicked or liked something, not a detailed\n",
                                        "rating. Early work such as *Collaborative Filtering for Implicit Feedback Datasets* (Hu,\n",
                                        "Koren, & Volinsky, 2008) and *BPR: Bayesian Personalized Ranking from Implicit\n",
                                        "Feedback* (Rendle, Freudenthaler, Gantner, & Schmidt-Thieme, 2009) showed how to use\n",
                                        "this kind of “yes/no” data to learn which users and items go well together. Their models\n",
                                        "learn a small list of numbers for each user and for each item, and then give a higher score\n",
                                        "to user–item pairs whose numbers line up well. At prediction time, the system picks the\n",
                                        "items with the highest scores for each user. Our main interaction based model is inspired by this\n",
                                        "same idea, where for each user and each project, we learn a short numeric description, and to\n",
                                        "recommend projects to a user we score all projects and keep the ones with the highest\n",
                                        "scores.\n",
                                        "\n",
                                        "**Popularity based recommendations:**  \n",
                                        "Other work on sites like YouTube, Pinterest, or Behance-style platforms has found that\n",
                                        "simply recommending the most popular items, meaning the ones that receive the most likes overall,\n",
                                        "can already work surprisingly well. Because many users interact with only a few items, and\n",
                                        "because attention is often focused on a small set of very popular items, “recommend what\n",
                                        "is globally popular” is commonly used as a simple starting point or a backup strategy. Our\n",
                                        "popularity based model follows this idea, since we rank projects by how many likes they\n",
                                        "have, and recommend the top ones to everyone. In our results, this approach is quite effective: \n",
                                        "on average, for each user, a large fraction of the top 10 projects we recommend\n",
                                        "this way are projects they actually liked in the held out test data. This supports the claim\n",
                                        "from prior work that likes tend to be heavily concentrated on a small set of very popular\n",
                                        "projects.\n",
                                        "\n",
                                        "**Using image information to make recommendations:**  \n",
                                        "More recent research combines interaction data with information extracted from the images\n",
                                        "themselves. In domains like fashion, art, and design, how something looks is very important,\n",
                                        "so using image information can help. Models such as VBPR (*VBPR: Visual Bayesian\n",
                                        "Personalized Ranking for Personalized Recommendation of Visual Content*; He &\n",
                                        "McAuley, 2016) use an image recognition network to turn each image into a long vector of\n",
                                        "numbers that captures aspects like style, color, and composition. They then combine this\n",
                                        "image based description with the interaction based model so that the system can\n",
                                        "recommend items that both match a user’s taste and look similar to things they have liked\n",
                                        "before, and can still recommend reasonable items even when there are few past likes for a\n",
                                        "given item. Other work on image popularity prediction, such as *What Makes an Image\n",
                                        "Popular?* (Khosla, Das Sarma, & Hamid, 2014), also shows that these kinds of image\n",
                                        "features are strongly related to whether an image will attract attention and engagement.\n",
                                        "\n",
                                        "Our visual only model is closest to this line of work on image popularity. In our case, we\n",
                                        "ignore user IDs and only look at image-based features, since we build a visual profile for each\n",
                                        "user by averaging the image features of the projects they liked, and then recommend\n",
                                        "projects whose image features are similar to that profile. We find that this image only\n",
                                        "approach does contain useful information, but it is not enough by itself: compared to our\n",
                                        "interaction-based model and our popularity based model, it suggests fewer projects that\n",
                                        "the user actually likes near the top of the ranked list.\n",
                                        "\n",
                                        "**Combining interaction and image information:**  \n",
                                        "A common idea in related works is to combine these different signals rather than choose\n",
                                        "only one of them. Many papers use a weighted combination of a score based on past\n",
                                        "interactions and a score based on content, such as image features. This lets the system\n",
                                        "balance between “people who liked X also liked Y” and “this looks similar to what you\n",
                                        "liked before,” and can help especially for users or items that do not have much interaction\n",
                                        "history. Our combined model follows this pattern, as for each user–project pair, we compute\n",
                                        "one score from the interaction based model and one from the image based model, and\n",
                                        "then take a weighted average of the two, controlled by a parameter that decides how much\n",
                                        "weight to give to each source of information. In line with prior work, we see that using a\n",
                                        "middle value for this weight, rather than relying purely on interactions or purely on images,\n",
                                        "gives the best overall ranking of projects for most users on our test data. However, our\n",
                                        "results also show that the pure popularity based model still gives the largest number of\n",
                                        "correct hits in the top 10 recommendations. This suggests that our simple way of combining\n",
                                        "signals does not yet fully exploit popularity information, a limitation that is also discussed in\n",
                                        "recent work on how to correctly handle very popular items when building recommendation\n",
                                        "systems.\n"
                              ]
                    }
          ],
          "metadata": {
                    "kernelspec": {
                              "display_name": "cse258",
                              "language": "python",
                              "name": "python3"
                    },
                    "language_info": {
                              "codemirror_mode": {
                                        "name": "ipython",
                                        "version": 3
                              },
                              "file_extension": ".py",
                              "mimetype": "text/x-python",
                              "name": "python",
                              "nbconvert_exporter": "python",
                              "pygments_lexer": "ipython3",
                              "version": "3.10.18"
                    }
          },
          "nbformat": 4,
          "nbformat_minor": 5
}
